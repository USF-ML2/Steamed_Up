{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'MegEllis'\n",
    "\n",
    "import json\n",
    "import collections\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Path for spark source folder\n",
    "os.environ['SPARK_HOME']= \"/Users/MegEllis/Desktop/spark-1.6.0-bin-hadoop2.6_2\"\n",
    "\n",
    "sys.path.append(\"/Users/MegEllis/Desktop/spark-1.6.0-bin-hadoop2.6_2/python/\")\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SQLContext, Row\n",
    "sqlContext = SQLContext(sc)\n",
    "conf = (SparkConf().setMaster(\"local\").setAppName(\"My app\").set(\"spark.executor.memory\", \"1g\"))\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we create a default dictionary that maps users to each game they've played and for how long over their lifetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_open = open('/Users/MegEllis/Desktop/aml_proj/userData.txt', 'r+')\n",
    "\n",
    "def nest_dict(filename):\n",
    "    listed_dict = []\n",
    "    for line in filename:\n",
    "        json_lines = json.loads(line)\n",
    "        rec_dict = collections.defaultdict(dict)\n",
    "        user = json_lines['user']\n",
    "        in_response = json_lines['ownedGames']['response']\n",
    "        if 'games' in in_response:\n",
    "            for i in in_response['games']:\n",
    "                rec_dict[user][i['name']] = i['playtime_forever']\n",
    "            listed_dict.append(rec_dict)\n",
    "    return listed_dict\n",
    "\n",
    "\n",
    "final_list = nest_dict(users_open)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we then transform this list of nested dictionaries into an RDD to more efficiently and quickly format the data and find relevent information. For example, we need to standardize the playtime for a given time since some games can only be played for a certain amount of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_RDD = sc.parallelize(final_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to run statisical analysis on the data, it must be placed in a tuple which is then transformed into an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tup_list = []\n",
    "for i in range(len(final_list)):\n",
    "    tup_list.extend(final_list[i].values()[0].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_count_RDD = sc.parallelize(tup_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this tuple we can calculate the average number of hours played per game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tottime_per_game = time_count_RDD.mapValues(lambda x: (x, 1))\\\n",
    "                .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])) \\\n",
    "                .filter(lambda x: x[1][0] != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_per_game = tottime_per_game.map(lambda x: (x[0], float(x[1][0])/float(x[1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_list = []\n",
    "for i in range(len(final_list)):\n",
    "    user = final_list[i].keys()[0]\n",
    "    tup_list = final_list[i].values()[0].items()\n",
    "    for j in range(len(tup_list)):\n",
    "        full_list.extend([(tup_list[j][0], user, tup_list[j][1])])\n",
    "\n",
    "        \n",
    "full_list_RDD = sc.parallelize(full_list).filter(lambda x: x[2] != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing: Now that we have the average playtime for each game, we get the proportion of the number of hours played per player for a given game over the game's average. To do this, we use spark sql to join the table that contains the information of users and and their playtime to the table that contains information of each game and its average playtime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users = full_list_RDD.map(lambda x: Row(game = x[0], user = x[1], playtime = x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Users = sqlContext.createDataFrame(users)\n",
    "Users.registerTempTable(\"users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_times = avg_per_game.map(lambda x: Row(game = x[0], avg_time = x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AvgTimes = sqlContext.createDataFrame(avg_times)\n",
    "AvgTimes.registerTempTable(\"AvgTimes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jointest=sqlContext.sql('''SELECT users.game, users.user, users.playtime, AvgTimes.avg_time\n",
    "                    FROM users LEFT JOIN AvgTimes\n",
    "                    ON users.game = AvgTimes.game\n",
    "                    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make this dataframe that resulted from the join into an RDD to easily extract info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_rdd = jointest.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_get_prop = full_rdd.map(lambda x: (x[0], x[1], x[2], x[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_prop = to_get_prop.map(lambda x: (x[0], (x[1], float(x[2] + 1)/float(x[3] +1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exit_dict = get_prop.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recreate the default dictionary so that we can perform the similarity, rating, and overall RMSE and mean error functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_key = collections.defaultdict(dict)\n",
    "game_key = collections.defaultdict(dict)\n",
    "for i in range(len(exit_dict)):\n",
    "    user_key[exit_dict[i][1][0]][exit_dict[i][0]] = exit_dict[i][1][1]\n",
    "    game_key[exit_dict[i][0]][exit_dict[i][1][0]] = exit_dict[i][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_time_prop = get_prop.map(lambda x: x[1][1]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_time_prop = get_prop.map(lambda x: x[1][1]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1384.6459279818016"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_time_prop - min_time_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "138.5 per each bucket - the range of the most average hours played and the least divided by 10: the number of buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "going to test both splitting into evently sized bins and just testing the ratios on their own.\n",
    "First, make sure we can attain similarity and rating for a certain number of users - treated as the test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity(i, j, dicto):\n",
    "    i_rating_avg = np.mean(dicto[i].values())\n",
    "    j_rating_avg = np.mean(dicto[j].values())\n",
    "    k = list(set(dicto[i].keys()) & set(dicto[j].keys()))\n",
    "    if k == []:\n",
    "        similar = 1\n",
    "        exit\n",
    "    else:\n",
    "        num = 0\n",
    "        denom1 = 0\n",
    "        denom2 = 0\n",
    "        for t in range(len(k)):\n",
    "            num = num + ((dicto[i][k[t]] - i_rating_avg)) * ((dicto[j][k[t]] - j_rating_avg))\n",
    "            denom1 = denom1 + (((dicto[i][k[t]] - i_rating_avg)**2))\n",
    "            denom2 = denom2 + ((dicto[j][k[t]] - j_rating_avg)**2)\n",
    "        denom = (denom1 * denom2)\n",
    "        denom_sqrt = math.sqrt(denom)\n",
    "        similar = (num+1)/(denom_sqrt + 1)\n",
    "    return similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rating(user, game, game_key, user_key):\n",
    "    user_avg_rating = np.mean(user_key[user].values())\n",
    "    game_user_list = game_key[game].keys()\n",
    "    term_1 = 0\n",
    "    term_2 = 0\n",
    "    for m in game_user_list:\n",
    "        sim = similarity(user, m, user_key)\n",
    "        term_1 = term_1 + abs(sim)\n",
    "        term_2 = term_2 + (sim * ((game_key[game][m]) - np.mean(user_key[m].values())))\n",
    "    rating = user_avg_rating + ((1/term_1) * term_2)\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_list = user_key.keys()[:1000]\n",
    "game_list = game_key.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diffies = []\n",
    "diffies2 = []\n",
    "for u in user_list:\n",
    "    for g in user_key[u]:\n",
    "        actual = user_key[u][g]\n",
    "        new = get_rating(u, g, game_key, user_key)\n",
    "        diffies.append(abs(new - actual))\n",
    "        diffies2.append((new - actual)**2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_abs_error = sum(diffies)/len(diffies)\n",
    "mean_abs_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RMSD = math.sqrt(sum(diffies2)/len(diffies2))\n",
    "RMSD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
